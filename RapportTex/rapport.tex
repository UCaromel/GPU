\documentclass[10pt,a4paper]{article}

\usepackage[main=french]{babel}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\usepackage{amsmath,amssymb,amsfonts,helvet,color}
\usepackage{amsthm}%\usepackage[pdftex]{graphicx}
\usepackage{graphicx}
\usepackage{graphics}
\usepackage{indentfirst}
\usepackage{amsmath,amssymb,amsfonts,subeqnarray}
\usepackage[dvipsnames]{xcolor}
\usepackage{listings}
\usepackage{enumitem}
\usepackage{bm}  % Pour le texte en gras
\usepackage{xcolor}
\usepackage[normalem]{ulem}
\usepackage{pdfpages}
\usepackage{subcaption}
\usepackage{datatool}
\usepackage{tabularx}
\usepackage{setspace}




\usepackage{geometry}
\geometry{top=3cm, bottom=3cm, left=2.25cm , right=2.25cm}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=BlueViolet,
    filecolor=OrangeRed,      
    urlcolor=blue,
    }
\title{Rapport de projet CPU/GPU}
\author{\\Matthieu PETIT\\Djemsay Morvan\\Ulysse Caromel\\\\\\
Encadrant : Mariko Dunseath\\\\\\}

\begin{document}

\setstretch{1.3}


% \maketitle

\begin{titlepage}

    \begin{center}
        \begin{center}
            \includegraphics[height=2.5cm]{../Images/univ-rennes1.png}
            
        \end{center}
        \begin{center}
            \textbf{UNIVERSITE RENNES 1 }
        \end{center}
        \textsc{\Large }\\[2.5cm]
    % Title
    \rule{\linewidth}{0.3mm} \\[0.4cm]
    { \huge \bfseries Rapport de fin de projet CPU/GPU \\[0.4cm] }
    \rule{\linewidth}{0.3mm} \\[3cm]
    
    
    % Author and supervisor
    \noindent
    \begin{center}
        \textbf{Petit} Matthieu\\
        \textbf{Caromel} Ulysse\\
        \textbf{Morvan} Djemsay\\
    \end{center}
        
    \color{black}
    \centering
    \vfill
    \large \textbf{Encadrant} - ~\textsc{Mariko Dunseath} 
    
    \vfill
    
    % Bottom of the page
    {\textbf{\large {Année universitaire} 2023-2024}}
    
    \end{center}
\end{titlepage}

\newpage

\tableofcontents

\newpage

\section{Partie théorique}

\subsection{Méthode de quadrature de Simpson}

La méthode de quadrature de Simpson est une technique numérique utilisée pour estimer l'intégrale numériquement. Elle est basée sur l'approximation d'une fonction par un polynôme quadratique entre chaque paire de points adjacents.

Supposons que nous ayons une fonction $f(x)$ que nous voulons intégrer sur l'intervalle $[a, b]$. La méthode de Simpson divise cet intervalle en sous-intervalles de largeur égale $h = \frac{b - a}{n}$, où $n$ est un nombre pair.

L'approximation de l'intégrale sur chaque sous-intervalle $[x_i, x_{i+2}]$ est donnée par :
\begin{align*}
\int_{x_i}^{x_{i+2}} f(x) \,dx \approx \frac{h}{3} \left[ f(x_i) + 4f(x_{i+1}) + f(x_{i+2}) \right]
\end{align*}

La somme de ces approximations sur tous les sous-intervalles donne l'estimation finale de l'intégrale :
\begin{align*}
\int_{a}^{b} f(x) \,dx \approx \frac{h}{3} \left[ f(a) + 4f(x_1) + 2f(x_2) + \ldots + 2f(x_{n-2}) + 4f(x_{n-1}) + f(b) \right]
\end{align*}

La méthode de Simpson est souvent plus précise que les méthodes de quadrature plus simples comme la méthode des rectangles, car elle prend en compte les variations de la fonction sur chaque sous-intervalle.


\subsection{Méthode de Gauss 2D}


La méthode de quadrature Gaussienne en deux dimensions (Gauss 2D) est utilisée pour estimer numériquement l'intégrale d'une fonction $f(x, y)$ sur une région bidimensionnelle définie par $a \leq x \leq b$ et $c \leq y \leq d$.

Supposons que nous ayons une fonction à intégrer sur cette région. La méthode de Gauss 2D utilise un ensemble de points et de poids associés pour approximer l'intégrale. La formule générale pour cette approximation est donnée par :
\begin{align*}
\iint_{R} f(x, y) \,dx\,dy \approx \sum_{i=1}^{n} \sum_{j=1}^{m} w_{ij} \cdot f(x_i, y_j)
\end{align*}

où $n$ et $m$ sont le nombre de points dans les directions $x$ et $y$, respectivement. Les points $x_i$ et $y_j$ sont les emplacements des points de quadrature, et $w_{ij}$ sont les poids associés à ces points.

Une formule spécifique de quadrature Gaussienne 2D pour un quadrilatère est donnée par :
\begin{align*}
\iint_{R} f(x, y) \,dx\,dy \approx \sum_{i=1}^{n} \sum_{j=1}^{m} w_{ij} \cdot f\left(\frac{1}{2}(1 + \xi_i)x + \frac{1}{2}(1 - \xi_i)y, \frac{1}{2}(1 + \eta_j)x + \frac{1}{2}(1 - \eta_j)y\right)
\end{align*}

où $\xi_i$ et $\eta_j$ sont les points de quadrature et $w_{ij}$ sont les poids associés.

La méthode de quadrature Gaussienne 2D offre une précision supérieure à la quadrature de Gauss unidimensionnelle, et elle est souvent utilisée pour résoudre numériquement des intégrales sur des domaines bidimensionnels complexes.


\subsection{Méthode de Runge-Kutta}



La méthode de Runge-Kutta est une technique numérique utilisée pour résoudre des équations différentielles ordinaires (EDO). La forme la plus courante est la méthode de Runge-Kutta d'ordre 4 (RK4), qui est souvent utilisée en raison de son équilibre entre précision et complexité.

Supposons que nous ayons une EDO du premier ordre sous la forme :
\begin{align*}
\frac{dy}{dt} = f(t, y)
\end{align*}

La méthode RK4 consiste en les étapes suivantes, où $h$ est la taille du pas de discrétisation :
\begin{align*}
k_1 &= h \cdot f(t_n, y_n) \\
k_2 &= h \cdot f(t_n + \frac{h}{2}, y_n + \frac{k_1}{2}) \\
k_3 &= h \cdot f(t_n + \frac{h}{2}, y_n + \frac{k_2}{2}) \\
k_4 &= h \cdot f(t_n + h, y_n + k_3)
\end{align*}

La mise à jour de la solution à chaque pas est alors donnée par :
\begin{align*}
y_{n+1} = y_n + \frac{1}{6}(k_1 + 2k_2 + 2k_3 + k_4)
\end{align*}

où $y_n$ est la valeur de la solution à l'instant $t_n$.

Cette méthode offre une meilleure précision par rapport aux méthodes de pas fixe plus simples, mais elle nécessite également plus de calculs. Cependant, elle est largement utilisée en pratique pour sa robustesse et sa polyvalence.


\subsection{Méthode d'intégration de Monte-Carlo}

La méthode d'intégration de Monte Carlo est une technique utilisée en mathématiques pour estimer des valeurs numériques complexes, notamment les intégrales de fonctions dans des domaines à plusieurs dimensions. Elle repose sur des principes probabilistes et tire son nom du célèbre casino de Monte Carlo à Monaco, associant le hasard à des calculs numériques.

L'idée principale de cette méthode consiste à estimer une valeur en utilisant des échantillons aléatoires dans un domaine donné. Prenons l'exemple d'une intégrale définie sur un domaine $D$ dans le plan. Plutôt que d'utiliser des méthodes traditionnelles d'intégration, on peut estimer la valeur de cette intégrale en générant aléatoirement des points dans $D$.

Imaginons que nous voulions calculer l'intégrale $I = \int\int_{D} f(x,y) \, dx \, dy$. La méthode de Monte Carlo fonctionne approximativement comme suit :

\begin{enumerate}
    \item Génération de points aléatoires : On génère un grand nombre de points aléatoires $(x_i, y_i)$ dans le domaine $D$ selon une distribution choisie (souvent uniforme ou gaussienne).
    \item Évaluation de la fonction : On évalue la fonction $f(x,y)$ pour chaque point $(x_i, y_i)$.
    \item Calcul de la moyenne pondérée : On calcule la moyenne des valeurs de $f(x,y)$ évaluées pour les points générés et on multiplie cette moyenne par la mesure de l'ensemble $D$. Cette mesure est souvent estimée par le rapport entre le nombre de points dans $D$ et le nombre total de points générés.
\end{enumerate}

La formule d'estimation de Monte Carlo pour l'intégrale devient alors :
$$I \approx A \cdot \frac{1}{N} \sum_{i=1}^{N} f(x_i, y_i)$$
Où $A$ est la mesure de $D$, $N$ est le nombre de points générés et $(x_i, y_i)$ sont les coordonnées des points aléatoires.

L'avantage clé de cette méthode est sa flexibilité et sa capacité à traiter des problèmes complexes dans des espaces à dimensions élevées. Cependant, sa précision dépend fortement du nombre de points aléatoires générés : plus le nombre de points est élevé, plus l'estimation de l'intégrale sera précise, mais cela peut nécessiter beaucoup de ressources computationnelles.

La méthode de Monte Carlo offre une approche probabiliste puissante pour estimer numériquement des quantités complexes en utilisant des échantillons aléatoires. Son utilisation s'étend dans de nombreux domaines, de la physique à la finance, en raison de sa flexibilité et de sa capacité à traiter des problèmes difficiles à résoudre analytiquement.


\section{Outils utilisés}

\subsection{Open MP (CPU)}

OpenMP (Open Multi-Processing) est une API (Interface de Programmation Applicative) qui facilite la programmation parallèle en C, C++, et Fortran. Son objectif principal est de permettre aux développeurs d'exploiter les architectures parallèles des processeurs multi-cœurs de manière simple et portable.

Voici quelques points clés à propos d'OpenMP :

\begin{itemize}

    \item \textbf{Parallelisme explicite :} OpenMP permet aux programmeurs d'exprimer le parallélisme dans leur code de manière explicite à l'aide de directives de compilation. Ces directives sont des annotations spéciales ajoutées au code source.
    
    \item \textbf{Directives pragmatiques :} Les directives OpenMP sont écrites sous forme de commentaires pragmatiques qui sont ignorés par les compilateurs qui ne supportent pas OpenMP. Cela permet au code source d'être compilé et exécuté sur des machines qui ne prennent pas en charge OpenMP sans erreur.
    
    \item \textbf{Tâches parallèles et boucles :} OpenMP permet la parallélisation de boucles et de sections de code avec des directives telles que \verb|#pragma omp parallel for| pour paralléliser une boucle, ou \verb|#pragma omp parallel sections| pour diviser le code en sections parallèles.
    
    \item \textbf{Gestion automatique de l'ordonnancement :} OpenMP offre une gestion automatique de l'ordonnancement des tâches parallèles, simplifiant ainsi la tâche du programmeur en ce qui concerne la gestion des threads et l'ordonnancement des tâches.
    
    \item \textbf{Support multi-plateforme :} OpenMP est supporté par de nombreux compilateurs sur différentes plates-formes, ce qui rend le code portable entre différentes architectures.

\end{itemize}


En résumé, OpenMP est une solution efficace pour ajouter du parallélisme aux applications existantes sans avoir à réécrire complètement le code. Cela facilite la création de programmes performants sur des architectures multi-cœurs.


\subsection{MPI (CPU)}


MPI (Message Passing Interface) est une norme pour la programmation parallèle utilisée pour développer des applications sur des architectures distribuées ou parallèles. Contrairement à OpenMP qui se concentre sur les architectures multi-cœurs partagées, MPI est conçu pour gérer la communication entre différents processus s'exécutant sur des nœuds distincts d'un cluster.

Voici quelques points clés à propos de MPI :

\begin{itemize}
    
    \item \textbf{Modèle de programmation distribuée :} MPI s'appuie sur un modèle de programmation distribuée où chaque nœud d'un système peut avoir sa propre mémoire et exécute son propre processus. Les processus communiquent entre eux à l'aide de messages.
    
    \item \textbf{Passage de messages :} La communication entre les processus est réalisée via le passage explicite de messages. Les processus s'envoient des messages pour échanger des données ou coordonner leurs activités.
    
    \item \textbf{Abstraction des communications :} MPI fournit une abstraction des communications en permettant aux programmeurs d'utiliser des opérations de communication comme \verb|MPI_Send| et \verb|MPI_Recv| pour envoyer et recevoir des messages.
    
    \item \textbf{Point à point et collectif :} MPI prend en charge à la fois les communications point à point (entre deux processus) et les communications collectives (impliquant plusieurs processus). Les opérations collectives incluent des fonctionnalités telles que la diffusion, la réduction, la barrière, etc.
    
    \item \textbf{Indépendance d'architecture :} Comme OpenMP, MPI est conçu pour être indépendant de l'architecture matérielle, ce qui signifie qu'un code MPI peut être exécuté sur divers types de clusters sans nécessiter de modifications significatives.
\end{itemize}


En résumé, MPI est une norme de programmation parallèle qui permet de développer des applications distribuées en utilisant un modèle de passage de messages. Il est largement utilisé dans le domaine de la simulation, de l'analyse de données massives et d'autres domaines nécessitant une puissance de calcul parallèle sur des clusters de machines.


\subsection{CUDA (GPU)}

CUDA (Compute Unified Device Architecture) est une architecture de calcul parallèle développée par NVIDIA. Elle permet d'utiliser les GPU (Graphical Processing Unit) pour accélérer des tâches de calcul intensif. CUDA est particulièrement utilisé pour le calcul parallèle sur les cartes graphiques NVIDIA.

Voici quelques points clés à propos de CUDA :

\begin{itemize}
    
    \item \textbf{Modèle de programmation parallèle sur GPU :} CUDA permet aux programmeurs d'utiliser la puissance de calcul massivement parallèle des GPU. Il s'appuie sur un modèle de programmation parallèle où des threads s'exécutent simultanément sur les cœurs du GPU.
    
    \item \textbf{Kernels CUDA :} Le code CUDA s'exécute sur le GPU sous la forme de kernels. Un kernel est une fonction qui est exécutée par un grand nombre de threads sur le GPU.
    
    \item \textbf{Hétérogénéité :} CUDA permet l'exécution de code sur le CPU (hôte) et le GPU (dispositif) simultanément. Le CPU gère les tâches de coordination et de gestion générale, tandis que le GPU effectue des calculs massivement parallèles.
    
    \item \textbf{Hiérarchie des threads et des blocs :} Les threads CUDA sont organisés en blocs, et les blocs peuvent être organisés en grilles. Cette hiérarchie permet une gestion fine du parallélisme.
    
    \item \textbf{Gestion explicite de la mémoire :} Les programmeurs doivent gérer explicitement le transfert des données entre le CPU et le GPU, ainsi que la gestion de la mémoire sur le GPU (mémoire globale, mémoire partagée, etc.).
\end{itemize}


En résumé, CUDA permet d'exploiter la puissance de calcul des GPU pour accélérer des tâches parallèles. Il offre un modèle de programmation hétérogène avec une gestion explicite de la mémoire et des directives spéciales pour définir des kernels qui s'exécutent sur le GPU. Cette approche est particulièrement efficace pour des tâches intensives en calcul, comme le rendu graphique, la simulation physique, et l'apprentissage profond.

\clearpage
\section{Implémentation et résultats}
On présente ici les résultats pour chaque méthode et chaque bibiliothèque de parallélisation.

Pour chaque méthode, on présente une étude de l'erreur en fonction du nombre de subdivision ainsi qu'une étude du temps en fonction du nombre de subdivision.

Les outils OpenMP et MPI ont été utilisés avec un maximum de 8 processeurs, tandis que pour CUDA, la configuration utilisé est la suivante : 

A COMPLETER

On présente ensuite une étude sur le temps d'éxécution en fonction du nombre de subdivision, ainsi qu'une étude sur l'erreur en fonction du nombre de subdivision et cela pour chaque méthode (Simpson, Runge Kutta, Gauss 2D, Monte Carlo) et pour chaque parallélisation (Cuda, OpenMP, MPI).

Nous affichons dans un premier temps tout les graphiques obtnus, une analyse sera donnée par la suite en partie (\ref{sec:analyse}).

\subsection{Méthode de Simpson}

\subsubsection{Open MP}


  \begin{figure}[ht!]
    \centering

    \subcaptionbox{Erreur \label{fig:errSimpMP}}{\includegraphics[width=0.45\linewidth]{../Images/error_simp_Op_MP.png}}%
    \hfill 
    \subcaptionbox{Temps \label{fig:timSimpMP}}{\includegraphics[width=0.45\linewidth]{../Images/time_simp_Op_MP.png}}
  
    \caption{Méthode de Simpson : Open MP}
    \label{fig:simpMP}
  \end{figure}



\subsubsection{MPI}

\begin{figure}[ht!]
    \centering

    \subcaptionbox{Erreur \label{fig:errSimpMPI}}{\includegraphics[width=0.45\linewidth]{../Images/error_simp_MPI.png}}%
    \hfill 
    \subcaptionbox{Temps \label{fig:timSimpMPI}}{\includegraphics[width=0.45\linewidth]{../Images/time_simp_MPI.png}}
  
    \caption{Méthode de Simpson : MPI}
    \label{fig:simpMPI}
  \end{figure}

\subsubsection{Cuda}

\subsection{Gauss}

\subsubsection{Open MP}

\begin{figure}[ht!]
    \centering

    \subcaptionbox{Erreur \label{fig:errGaussMP}}{\includegraphics[width=0.45\linewidth]{../Images/error_gauss_Op_MP.png}}%
    \hfill % Ajoute une espace horizontale entre les sous-figures
    \subcaptionbox{Temps \label{fig:timGaussMP}}{\includegraphics[width=0.45\linewidth]{../Images/time_gauss_Op_MP.png}}
  
    \caption{Méthode de Gaus 2D : Open MP}
    \label{fig:gaussMP}
  \end{figure}

\subsubsection{MPI}

\begin{figure}[ht!]
    \centering

    \subcaptionbox{Erreur \label{fig:errGaussMPI}}{\includegraphics[width=0.45\linewidth]{../Images/error_gauss_MPI.png}}%
    \hfill % Ajoute une espace horizontale entre les sous-figures
    \subcaptionbox{Temps \label{fig:timGaussMPI}}{\includegraphics[width=0.45\linewidth]{../Images/time_gauss_MPI.png}}
  
    \caption{Méthode de Gauss 2D : MPI}
    \label{fig:gaussMPI}
  \end{figure}

\subsubsection{Cuda}

\subsection{Runge Kutta}

\subsubsection{Open MP}

\begin{figure}[ht!]
    \centering

    \subcaptionbox{Erreur \label{fig:errRKMP}}{\includegraphics[width=0.45\linewidth]{../Images/error_RK_Op_MP.png}}%
    \hfill % Ajoute une espace horizontale entre les sous-figures
    \subcaptionbox{Temps \label{fig:timRKMP}}{\includegraphics[width=0.45\linewidth]{../Images/time_RK_Op_MP.png}}
  
    \caption{Méthode de Runge Kutta : Open MP}
    \label{fig:RKMP}
  \end{figure}

\subsubsection{MPI}

\begin{figure}[ht!]
    \centering

    \subcaptionbox{Erreur \label{fig:errRKMPI}}{\includegraphics[width=0.45\linewidth]{../Images/error_RK_MPI.png}}%
    \hfill % Ajoute une espace horizontale entre les sous-figures
    \subcaptionbox{Temps \label{fig:timRKMPI}}{\includegraphics[width=0.45\linewidth]{../Images/time_RK_MPI.png}}
  
    \caption{Méthode de Runge Kutta : MPI}
    \label{fig:RKMPI}
  \end{figure}

\subsubsection{Cuda}

\subsection{Monte Carlo} 

\subsubsection{Open MP}

\begin{figure}[ht!]
    \centering

    \subcaptionbox{Erreur \label{fig:errMCMP}}{\includegraphics[width=0.45\linewidth]{../Images/error_montecarlo_Op_MP.png}}%
    \hfill % Ajoute une espace horizontale entre les sous-figures
    \subcaptionbox{Temps \label{fig:timMCMP}}{\includegraphics[width=0.45\linewidth]{../Images/time_montecarlo_Op_MP.png}}
  
    \caption{Méthode de Monte Carlo : Open MP}
    \label{fig:MCMP}
  \end{figure}

\subsubsection{MPI}

\begin{figure}[ht!]
    \centering

    \subcaptionbox{Erreur \label{fig:errMCMPI}}{\includegraphics[width=0.45\linewidth]{../Images/error_montecarlo_MPI.png}}%
    \hfill % Ajoute une espace horizontale entre les sous-figures
    \subcaptionbox{Temps \label{fig:timMCMPI}}{\includegraphics[width=0.45\linewidth]{../Images/time_montecarloMPI.png}}
  
    \caption{Méthode de Monte Carlo : MPI}
    \label{fig:MCMPI}
  \end{figure}

\subsubsection{Cuda}

A COMPLETER


\subsection{Analyse des résultats} \label{sec:analyse}

A COMPLETER

\section{Quelques explications du code}


\subsection{Exécution}

Entrez dans le fichier \verb|parametres_Machine| le nombre de processeur max que vous souhaitez utiliser.

Des scripts bash sont disponibles dans le dossier `Bashs`, ils permettent de lancer les codes pour chaque méthode et chaque paralélisation : 
\begin{itemize}
  \item Simpson : 
  \item Gauss2D :
  \item Runge Kutta 
  \item MonteCarlo 
\end{itemize}

Pour les codes en CUDA, ils se trouvent dans le dossier Cuda.

Des scritps PowerShell sont également disponibles dans le dossier \verb|PowerShell| afin de pouvoir éxécuter les codes sous Windows.

\subsection{Graph Python}

Le fichier \verb|graph.py| dans le sous répertoire \verb|CodesPython| permet d'afficher les données dans le répertoire \verb|Results|. 
Il prend en entrée le nom préfix des données que vous voulez afficher.
Par exemple pour afficher les données pour la méthode de Simpson avec Open MP, placez vous dans le répertoire \verb|CodesPython| et tappez : 
\begin{center}
\verb|python3 graph.py "simp_Op_MP"|
\end{center}

\subsection{Remarques}
Le code pour la méthode de Gauss 2D utilise la librairie Eigen, il sera nécessaire de linker la librairie et donc de devoir modifier légèrement les fichiers \verb|gauss2DMPI.cpp| et \verb|gauss2DOpenMP.cpp|.

\end{document}



